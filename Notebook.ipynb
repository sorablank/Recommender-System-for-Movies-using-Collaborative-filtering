{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommender System for Movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_30808\\2681200409.py:1: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  movies = pd.read_csv('Dataset\\movies_metadata.csv')\n"
     ]
    }
   ],
   "source": [
    "movies = pd.read_csv('Dataset\\movies_metadata.csv')\n",
    "ratings = pd.read_csv('Dataset/ratings.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Merging datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating   timestamp      id                 title\n",
      "0       1      110     1.0  1425941529   110.0     Three Colors: Red\n",
      "1       1      147     4.5  1425942435   147.0         The 400 Blows\n",
      "2       1      858     5.0  1425941523   858.0  Sleepless in Seattle\n",
      "3       1     1221     5.0  1425941546     NaN                   NaN\n",
      "4       1     1246     5.0  1425941556  1246.0          Rocky Balboa\n"
     ]
    }
   ],
   "source": [
    "# Convert the 'id' column in the movies DataFrame to int64\n",
    "movies['id'] = pd.to_numeric(movies['id'], errors='coerce', downcast='integer')\n",
    "\n",
    "# Merge datasets\n",
    "data = pd.merge(ratings, movies[['id', 'title']], left_on='movieId', right_on='id', how='left')\n",
    "\n",
    "# Display the first few rows\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Creating a new CSV file utilising relevant features to us for the final recommender system app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_17204\\1623673663.py:7: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  movies_metadata = pd.read_csv('Dataset/movies_metadata.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load ratings.csv\n",
    "ratings = pd.read_csv('Dataset/ratings.csv')\n",
    "\n",
    "# Load movies_metadata.csv\n",
    "movies_metadata = pd.read_csv('Dataset/movies_metadata.csv')\n",
    "\n",
    "# Convert 'movieId' column in ratings to object type\n",
    "ratings['movieId'] = ratings['movieId'].astype('str')\n",
    "\n",
    "# Merge the two dataframes on the 'movieId' and 'title' columns\n",
    "merged_data = pd.merge(ratings, movies_metadata, left_on='movieId', right_on='title')\n",
    "\n",
    "# Save the merged dataframe to a new CSV file\n",
    "merged_data.to_csv('Dataset/recommendations_hash.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Performing some feature engineering on the new dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Creating a new column that extracts just name of the genres from the entire value and stores it in the genres_list column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_30808\\2861186361.py:5: DtypeWarning: Columns (5,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  recommendations = pd.read_csv('Dataset/recommendations.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   genres  \\\n",
      "0       [{'id': 12, 'name': 'Adventure'}, {'id': 18, '...   \n",
      "1       [{'id': 12, 'name': 'Adventure'}, {'id': 18, '...   \n",
      "2       [{'id': 12, 'name': 'Adventure'}, {'id': 18, '...   \n",
      "3       [{'id': 12, 'name': 'Adventure'}, {'id': 18, '...   \n",
      "4       [{'id': 12, 'name': 'Adventure'}, {'id': 18, '...   \n",
      "...                                                   ...   \n",
      "364358  [{'id': 18, 'name': 'Drama'}, {'id': 35, 'name...   \n",
      "364359  [{'id': 18, 'name': 'Drama'}, {'id': 35, 'name...   \n",
      "364360  [{'id': 18, 'name': 'Drama'}, {'id': 35, 'name...   \n",
      "364361  [{'id': 18, 'name': 'Drama'}, {'id': 35, 'name...   \n",
      "364362  [{'id': 18, 'name': 'Drama'}, {'id': 35, 'name...   \n",
      "\n",
      "                                     genres_list  \n",
      "0       [Adventure, Drama, Action, History, War]  \n",
      "1       [Adventure, Drama, Action, History, War]  \n",
      "2       [Adventure, Drama, Action, History, War]  \n",
      "3       [Adventure, Drama, Action, History, War]  \n",
      "4       [Adventure, Drama, Action, History, War]  \n",
      "...                                          ...  \n",
      "364358           [Drama, Comedy, History, Music]  \n",
      "364359           [Drama, Comedy, History, Music]  \n",
      "364360           [Drama, Comedy, History, Music]  \n",
      "364361           [Drama, Comedy, History, Music]  \n",
      "364362           [Drama, Comedy, History, Music]  \n",
      "\n",
      "[364363 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Load recommendations.csv\n",
    "recommendations = pd.read_csv('Dataset/recommendations.csv')\n",
    "\n",
    "# Function to extract genres from the 'genres' column\n",
    "def extract_genres(genres_str):\n",
    "    genres_list = ast.literal_eval(genres_str)\n",
    "    return [genre['name'] for genre in genres_list]\n",
    "\n",
    "# Create a new 'genres_list' column\n",
    "recommendations['genres_list'] = recommendations['genres'].apply(extract_genres)\n",
    "\n",
    "# Display the dataframe with the new 'genres_list' column\n",
    "print(recommendations[['genres', 'genres_list']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Updating the above column in our CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the modified dataframe to the same CSV file\n",
    "recommendations.to_csv('Dataset/recommendations.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Adding a new column that appends path of images to the Base_URL to generate hyperlink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_30808\\4258541767.py:4: DtypeWarning: Columns (5,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  recommendations = pd.read_csv('Dataset/recommendations.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             poster_path  \\\n",
      "0       /4B553EK5EWUc28Jvl2vZ3xwDWF4.jpg   \n",
      "1       /4B553EK5EWUc28Jvl2vZ3xwDWF4.jpg   \n",
      "2       /4B553EK5EWUc28Jvl2vZ3xwDWF4.jpg   \n",
      "3       /4B553EK5EWUc28Jvl2vZ3xwDWF4.jpg   \n",
      "4       /4B553EK5EWUc28Jvl2vZ3xwDWF4.jpg   \n",
      "...                                  ...   \n",
      "364358  /pmWFuObcbvIxOysCvu8gQHT2QxQ.jpg   \n",
      "364359  /pmWFuObcbvIxOysCvu8gQHT2QxQ.jpg   \n",
      "364360  /pmWFuObcbvIxOysCvu8gQHT2QxQ.jpg   \n",
      "364361  /pmWFuObcbvIxOysCvu8gQHT2QxQ.jpg   \n",
      "364362  /pmWFuObcbvIxOysCvu8gQHT2QxQ.jpg   \n",
      "\n",
      "                                               hyperlinks  \n",
      "0       https://flixpatrol.com/runtime/cache/files/pos...  \n",
      "1       https://flixpatrol.com/runtime/cache/files/pos...  \n",
      "2       https://flixpatrol.com/runtime/cache/files/pos...  \n",
      "3       https://flixpatrol.com/runtime/cache/files/pos...  \n",
      "4       https://flixpatrol.com/runtime/cache/files/pos...  \n",
      "...                                                   ...  \n",
      "364358  https://flixpatrol.com/runtime/cache/files/pos...  \n",
      "364359  https://flixpatrol.com/runtime/cache/files/pos...  \n",
      "364360  https://flixpatrol.com/runtime/cache/files/pos...  \n",
      "364361  https://flixpatrol.com/runtime/cache/files/pos...  \n",
      "364362  https://flixpatrol.com/runtime/cache/files/pos...  \n",
      "\n",
      "[364363 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load recommendations.csv\n",
    "recommendations = pd.read_csv('Dataset/recommendations.csv')\n",
    "\n",
    "# Add a new 'hyperlinks' column\n",
    "base_url = 'https://flixpatrol.com/runtime/cache/files/posters/e/w350/'\n",
    "recommendations['hyperlinks'] = base_url + recommendations['poster_path']\n",
    "\n",
    "# Display the dataframe with the new 'hyperlinks' column\n",
    "print(recommendations[['poster_path', 'hyperlinks']])\n",
    "\n",
    "# Save the modified dataframe to the same CSV file\n",
    "recommendations.to_csv('Dataset/recommendations.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Reducing size of the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_17204\\28314022.py:3: DtypeWarning: Columns (5,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  recommendations = pd.read_csv('Dataset/recommendations.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load recommendations.csv\n",
    "recommendations = pd.read_csv('Dataset/recommendations.csv')\n",
    "\n",
    "\n",
    "# Drop rows where any column has no value in the 'hyperlinks' column\n",
    "recommendations = recommendations.dropna(subset=recommendations.columns.difference(['hyperlinks']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Content based filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18252                                The Dark Knight Rises\n",
       "1328                                        Batman Returns\n",
       "15511                           Batman: Under the Red Hood\n",
       "21194    Batman Unmasked: The Psychology of the Dark Kn...\n",
       "150                                         Batman Forever\n",
       "20232              Batman: The Dark Knight Returns, Part 2\n",
       "40974    LEGO DC Comics Super Heroes: Batman: Be-Leaguered\n",
       "41982    Batman Beyond Darwyn Cooke's Batman 75th Anniv...\n",
       "19792              Batman: The Dark Knight Returns, Part 1\n",
       "18035                                     Batman: Year One\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "\n",
    "# Create a TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "movies['overview'] = movies['overview'].fillna('')  # Replace missing values with an empty string\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(movies['overview'])\n",
    "\n",
    "# Calculate cosine similarity\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "def content_based_recommendations(title, cosine_sim=cosine_sim):\n",
    "    idx = movies.index[movies['title'] == title].tolist()[0]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:11]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return movies['title'].iloc[movie_indices]\n",
    "\n",
    "# Example usage\n",
    "content_based_recommendations(\"The Dark Knight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.25\n",
      "Recall: 1.00\n",
      "F1-score: 0.40\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "\n",
    "# Sample movies dataframe\n",
    "movies_data = {\n",
    "    'title': ['The Dark Knight', 'Inception', 'Interstellar', 'The Shawshank Redemption', 'Pulp Fiction'],\n",
    "    'overview': [\n",
    "        'Batman fights crime in Gotham City.',\n",
    "        'A thief who steals corporate secrets.',\n",
    "        'A team of explorers travel through a wormhole in space.',\n",
    "        'Two imprisoned men bond over a number of years.',\n",
    "        'Various interconnected stories of crime in Los Angeles.'\n",
    "    ]\n",
    "}\n",
    "\n",
    "movies = pd.DataFrame(movies_data)\n",
    "\n",
    "# Create a TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "movies['overview'] = movies['overview'].fillna('')  # Replace missing values with an empty string\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(movies['overview'])\n",
    "\n",
    "# Calculate cosine similarity\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "def content_based_recommendations(movie_title, cosine_sim=cosine_sim, movies=movies):\n",
    "    idx = movies.index[movies['title'] == movie_title].tolist()[0]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:11]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return movies['title'].iloc[movie_indices]\n",
    "\n",
    "# Assuming you have ground truth data (actual user ratings or preferences)\n",
    "ground_truth = {'The Dark Knight': 5, 'Inception': 4, 'Interstellar': 3, 'The Shawshank Redemption': 5, 'Pulp Fiction': 4}\n",
    "\n",
    "def evaluate_recommender_system(predictions, ground_truth):\n",
    "    # Get recommended movies for each title in the ground truth\n",
    "    recommended_movies = {title: predictions(title) for title in ground_truth.keys()}\n",
    "\n",
    "    # Flatten the recommended movies dictionary\n",
    "    recommended_movies_flat = [movie for movies in recommended_movies.values() for movie in movies]\n",
    "\n",
    "    # Calculate precision, recall, and F1-score\n",
    "    true_positives = len(set(ground_truth.keys()) & set(recommended_movies_flat))\n",
    "    precision = true_positives / len(recommended_movies_flat)\n",
    "    recall = true_positives / len(ground_truth)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    print(f'Precision: {precision:.2f}')\n",
    "    print(f'Recall: {recall:.2f}')\n",
    "    print(f'F1-score: {f1:.2f}')\n",
    "\n",
    "# Example usage\n",
    "evaluate_recommender_system(content_based_recommendations, ground_truth)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#From the above, we can see the Precision of our content based recommender system is only 25% which is extremely low. This is mainly because of our dataset not having enough filters to perform content based filtering with high accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(858, 4.689032010325887), (2762, 4.50341757279299), (1246, 4.452325764499476), (58559, 4.434139405158543), (68358, 4.311150611351167), (110, 4.203592071754154), (147, 4.17865017028571)]\n"
     ]
    }
   ],
   "source": [
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection import cross_validate, train_test_split\n",
    "\n",
    "# Load the dataset for Surprise\n",
    "reader = Reader()\n",
    "data_surprise = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "trainset, testset = train_test_split(data_surprise, test_size=0.25)\n",
    "\n",
    "# Build and train the collaborative filtering model\n",
    "algo = SVD()\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# Example usage\n",
    "def get_top_n(predictions, n=10):\n",
    "    top_n = {}\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        if uid not in top_n:\n",
    "            top_n[uid] = []\n",
    "        top_n[uid].append((iid, est))\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "    return top_n\n",
    "\n",
    "# Get top 10 recommendations for user 1\n",
    "top_n = get_top_n(predictions, n=10)\n",
    "print(top_n[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Hybrid Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The Dark Knight Rises', 'Batman: The Dark Knight Returns, Part 1', \"Batman Beyond Darwyn Cooke's Batman 75th Anniversary Short\", 'Batman Unmasked: The Psychology of the Dark Knight', 'Batman: The Dark Knight Returns, Part 2', 68358, 2762, 'Batman Forever', 'Batman: Year One', 'Batman: Under the Red Hood']\n"
     ]
    }
   ],
   "source": [
    "def hybrid_recommendations(title, user_id, content_model, collaborative_model):\n",
    "    # Get content-based recommendations\n",
    "    content_rec = content_model(title)\n",
    "\n",
    "    # Get collaborative filtering recommendations\n",
    "    collaborative_rec = [iid for (iid, _) in collaborative_model[user_id]]\n",
    "\n",
    "    # Combine recommendations\n",
    "    hybrid_rec = set(content_rec).union(set(collaborative_rec))\n",
    "\n",
    "    return list(hybrid_rec)[:10]\n",
    "\n",
    "# Example usage\n",
    "user_id = 1\n",
    "title = \"The Dark Knight\"\n",
    "hybrid_rec = hybrid_recommendations(title, user_id, content_based_recommendations, top_n)\n",
    "print(hybrid_rec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#We are done with understanding models and the dataset and we can now proceed to making the streamlit app"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
